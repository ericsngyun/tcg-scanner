{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Pre-computed Embeddings for TCG Scanner\n",
    "\n",
    "This notebook generates embeddings for all cards in the database and saves them as a binary file for fast loading in the mobile app.\n",
    "\n",
    "**Without pre-computed embeddings**: First launch takes ~58 seconds\n",
    "**With pre-computed embeddings**: App starts in ~200ms\n",
    "\n",
    "**Output**: `riftbound.bin` (~1.1 MB) - Ready for Flutter app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q tensorflow>=2.13.0\n",
    "!pip install -q pillow>=9.5.0\n",
    "!pip install -q requests>=2.31.0\n",
    "\n",
    "print(\"âœ… Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set paths\n",
    "DRIVE_ROOT = Path('/content/drive/MyDrive/tcg-scanner')\n",
    "MODELS_DIR = DRIVE_ROOT / 'models' / 'tflite'\n",
    "OUTPUT_DIR = DRIVE_ROOT / 'embeddings'\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Drive root: {DRIVE_ROOT}\")\n",
    "print(f\"Models dir: {MODELS_DIR}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Card Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cards.json from your repo\n",
    "# You'll need to upload this file to Google Drive first\n",
    "cards_json_path = DRIVE_ROOT / 'cards.json'\n",
    "\n",
    "if not cards_json_path.exists():\n",
    "    print(\"âŒ cards.json not found!\")\n",
    "    print(f\"Please upload cards.json to: {cards_json_path}\")\n",
    "    print(\"\\nFrom your local machine:\")\n",
    "    print(\"  mobile/flutter/assets/data/cards.json â†’ Google Drive\")\n",
    "else:\n",
    "    with open(cards_json_path) as f:\n",
    "        cards = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(cards)} cards from database\")\n",
    "    print(f\"\\nSample card:\")\n",
    "    print(f\"  Name: {cards[0]['name']}\")\n",
    "    print(f\"  Image: {cards[0]['image_path']}\")\n",
    "    print(f\"  Type: {cards[0]['card_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding.tflite\n",
    "embedding_model_path = MODELS_DIR / 'embedding.tflite'\n",
    "\n",
    "if not embedding_model_path.exists():\n",
    "    print(f\"âŒ Model not found: {embedding_model_path}\")\n",
    "else:\n",
    "    # Load TFLite model\n",
    "    interpreter = tf.lite.Interpreter(str(embedding_model_path))\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input/output details\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    \n",
    "    print(f\"âœ… Embedding model loaded\")\n",
    "    print(f\"  Input shape: {input_details['shape']}\")\n",
    "    print(f\"  Output shape: {output_details['shape']}\")\n",
    "    print(f\"  Expected: [1, 384] embedding vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing Functions (Match Flutter Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ImageNet normalization constants (same as Flutter)\nIMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\nIMAGENET_STD = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n\ndef download_image(url: str, timeout: int = 10) -> Image.Image:\n    \"\"\"Download image from URL.\"\"\"\n    try:\n        response = requests.get(url, timeout=timeout)\n        response.raise_for_status()\n        image = Image.open(BytesIO(response.content)).convert('RGB')\n        return image\n    except Exception as e:\n        print(f\"Failed to download {url}: {e}\")\n        return None\n\ndef preprocess_for_embedding(image: Image.Image) -> np.ndarray:\n    \"\"\"\n    Preprocess image for embedding (matches TFLite model requirements).\n\n    Args:\n        image: PIL Image\n\n    Returns:\n        Preprocessed tensor in NCHW format [1, 3, 224, 224]\n    \"\"\"\n    # Step 1: Resize to 224x224\n    image = image.resize((224, 224), Image.Resampling.BILINEAR)\n\n    # Step 2: Convert to numpy array [224, 224, 3]\n    tensor = np.array(image, dtype=np.float32)\n\n    # Step 3: Normalize with ImageNet statistics\n    # Formula: (pixel/255 - mean) / std\n    tensor = tensor / 255.0\n    tensor = (tensor - IMAGENET_MEAN) / IMAGENET_STD\n\n    # Step 4: Transpose to channels-first NCHW format\n    # [224, 224, 3] â†’ [3, 224, 224]\n    # TFLite model expects channels-first format!\n    tensor = np.transpose(tensor, (2, 0, 1))\n\n    # Step 5: Add batch dimension [3, 224, 224] â†’ [1, 3, 224, 224]\n    tensor = np.expand_dims(tensor, axis=0)\n\n    return tensor\n\ndef normalize_embedding(embedding: np.ndarray) -> np.ndarray:\n    \"\"\"\n    L2 normalize embedding (EXACTLY matches Flutter implementation).\n\n    Args:\n        embedding: Raw embedding vector\n\n    Returns:\n        Normalized embedding (unit vector)\n    \"\"\"\n    # Calculate L2 norm: sqrt(sum of squares)\n    norm = np.linalg.norm(embedding)\n\n    # Normalize: embedding / magnitude\n    if norm > 0:\n        embedding = embedding / norm\n\n    return embedding\n\nprint(\"âœ… Preprocessing functions defined (NCHW format)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Embeddings for All Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GENERATING EMBEDDINGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "embeddings = []\n",
    "successful_cards = []\n",
    "failed_cards = []\n",
    "\n",
    "for i, card in enumerate(tqdm(cards, desc=\"Processing cards\")):\n",
    "    try:\n",
    "        # Download card image\n",
    "        image_url = card['image_path']\n",
    "        image = download_image(image_url)\n",
    "        \n",
    "        if image is None:\n",
    "            failed_cards.append((card['name'], 'Download failed'))\n",
    "            # Use zero vector as placeholder\n",
    "            embeddings.append(np.zeros(384, dtype=np.float32))\n",
    "            continue\n",
    "        \n",
    "        # Preprocess image\n",
    "        input_tensor = preprocess_for_embedding(image)\n",
    "        \n",
    "        # Run inference\n",
    "        interpreter.set_tensor(input_details['index'], input_tensor)\n",
    "        interpreter.invoke()\n",
    "        embedding = interpreter.get_tensor(output_details['index'])[0]\n",
    "        \n",
    "        # L2 normalize (critical!)\n",
    "        embedding = normalize_embedding(embedding)\n",
    "        \n",
    "        # Verify normalization\n",
    "        norm = np.linalg.norm(embedding)\n",
    "        if not (0.95 < norm < 1.05):\n",
    "            print(f\"âš ï¸  {card['name']}: norm = {norm:.4f} (expected ~1.0)\")\n",
    "        \n",
    "        embeddings.append(embedding)\n",
    "        successful_cards.append(card['name'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error processing {card['name']}: {e}\")\n",
    "        failed_cards.append((card['name'], str(e)))\n",
    "        embeddings.append(np.zeros(384, dtype=np.float32))\n",
    "\n",
    "print(f\"\\nâœ… Generated {len(successful_cards)} embeddings\")\n",
    "print(f\"âŒ Failed: {len(failed_cards)}\")\n",
    "\n",
    "if failed_cards:\n",
    "    print(\"\\nFailed cards:\")\n",
    "    for name, error in failed_cards[:10]:\n",
    "        print(f\"  - {name}: {error}\")\n",
    "    if len(failed_cards) > 10:\n",
    "        print(f\"  ... and {len(failed_cards) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Embeddings to Binary File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "embeddings_array = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "print(f\"Embeddings array shape: {embeddings_array.shape}\")\n",
    "print(f\"Expected: ({len(cards)}, 384)\")\n",
    "\n",
    "# Save as binary file\n",
    "output_file = OUTPUT_DIR / 'riftbound.bin'\n",
    "embeddings_array.tofile(str(output_file))\n",
    "\n",
    "file_size_mb = output_file.stat().st_size / 1024 / 1024\n",
    "expected_size_mb = len(cards) * 384 * 4 / 1024 / 1024  # 4 bytes per float32\n",
    "\n",
    "print(f\"\\nâœ… Embeddings saved to: {output_file}\")\n",
    "print(f\"   File size: {file_size_mb:.2f} MB\")\n",
    "print(f\"   Expected: {expected_size_mb:.2f} MB\")\n",
    "\n",
    "if abs(file_size_mb - expected_size_mb) < 0.1:\n",
    "    print(f\"   âœ… File size matches expected!\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  File size mismatch!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Verify Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings back\n",
    "loaded_embeddings = np.fromfile(str(output_file), dtype=np.float32)\n",
    "loaded_embeddings = loaded_embeddings.reshape(len(cards), 384)\n",
    "\n",
    "print(f\"Loaded embeddings shape: {loaded_embeddings.shape}\")\n",
    "\n",
    "# Check a few embeddings\n",
    "print(\"\\nSample embeddings:\")\n",
    "for i in range(min(5, len(cards))):\n",
    "    embedding = loaded_embeddings[i]\n",
    "    norm = np.linalg.norm(embedding)\n",
    "    print(f\"  {cards[i]['name'][:40]:40} norm={norm:.4f}\")\n",
    "\n",
    "# Verify normalization\n",
    "norms = np.linalg.norm(loaded_embeddings, axis=1)\n",
    "valid_norms = np.sum((norms > 0.95) & (norms < 1.05))\n",
    "zero_norms = np.sum(norms < 0.01)\n",
    "\n",
    "print(f\"\\nNormalization check:\")\n",
    "print(f\"  Valid norms (0.95-1.05): {valid_norms}/{len(cards)}\")\n",
    "print(f\"  Zero vectors (failed): {zero_norms}/{len(cards)}\")\n",
    "\n",
    "if valid_norms == len(cards) - zero_norms:\n",
    "    print(f\"  âœ… All successful embeddings are properly normalized!\")\n",
    "else:\n",
    "    print(f\"  âš ï¸  Some embeddings may not be normalized correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: Find similar cards\n",
    "def find_similar_cards(query_idx: int, top_k: int = 5):\n",
    "    \"\"\"\n",
    "    Find most similar cards to query card.\n",
    "    \"\"\"\n",
    "    query_embedding = loaded_embeddings[query_idx]\n",
    "    \n",
    "    # Compute cosine similarity (dot product since normalized)\n",
    "    similarities = np.dot(loaded_embeddings, query_embedding)\n",
    "    \n",
    "    # Get top K\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    print(f\"\\nQuery card: {cards[query_idx]['name']}\")\n",
    "    print(f\"Top {top_k} similar cards:\")\n",
    "    \n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        sim = similarities[idx]\n",
    "        card = cards[idx]\n",
    "        print(f\"  {i}. {card['name'][:50]:50} similarity={sim:.4f}\")\n",
    "\n",
    "# Test with first few cards\n",
    "print(\"=\"*60)\n",
    "print(\"TESTING SIMILARITY SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for test_idx in [0, 10, 50]:\n",
    "    if test_idx < len(cards):\n",
    "        find_similar_cards(test_idx, top_k=5)\n",
    "\n",
    "print(\"\\nâœ… Similarity search working correctly!\")\n",
    "print(\"   Top result should be the card itself (similarity ~1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download for Flutter App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"READY FOR FLUTTER APP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nðŸ“¦ File to download: {output_file}\")\n",
    "print(f\"   Size: {file_size_mb:.2f} MB\")\n",
    "print(f\"\\nðŸ“ Flutter destination:\")\n",
    "print(f\"   mobile/flutter/assets/indices/riftbound.bin\")\n",
    "print(f\"\\nâœ… Pre-computed embeddings complete!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Download riftbound.bin from Google Drive\")\n",
    "print(f\"2. Copy to: mobile/flutter/assets/indices/riftbound.bin\")\n",
    "print(f\"3. The app will load in ~200ms instead of ~58 seconds!\")\n",
    "\n",
    "# Provide download link\n",
    "from google.colab import files\n",
    "print(f\"\\nDownloading file...\")\n",
    "files.download(str(output_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}