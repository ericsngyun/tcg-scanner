{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TCG Card Detection Training\n",
        "\n",
        "Train YOLOv8-nano for card detection using synthetic training data.\n",
        "\n",
        "**Prerequisites:**\n",
        "- Card images in Google Drive\n",
        "- Optional: Background images for synthetic scene generation\n",
        "\n",
        "**Estimated Time:** ~4-6 hours for full training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q ultralytics pyyaml tqdm opencv-python pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set paths\n",
        "DRIVE_PROJECT = '/content/drive/MyDrive/tcg-scanner'\n",
        "WORK_DIR = '/content/tcg-scanner'\n",
        "\n",
        "import os\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy data from Drive (if not already in work dir)\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Copy card images\n",
        "cards_src = Path(DRIVE_PROJECT) / 'ml/data/images/riftbound'\n",
        "cards_dst = Path(WORK_DIR) / 'data/images/riftbound'\n",
        "\n",
        "if cards_src.exists() and not cards_dst.exists():\n",
        "    print(\"Copying card images from Drive...\")\n",
        "    shutil.copytree(cards_src, cards_dst)\n",
        "    print(f\"Copied to {cards_dst}\")\n",
        "else:\n",
        "    print(f\"Cards directory: {cards_dst} (exists: {cards_dst.exists()})\")\n",
        "\n",
        "# Count images\n",
        "if cards_dst.exists():\n",
        "    num_images = sum(1 for _ in cards_dst.rglob('*.jpg'))\n",
        "    print(f\"Found {num_images} card images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Synthetic Detection Data\n",
        "\n",
        "Create training scenes by compositing cards onto backgrounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Synthetic scene generator (simplified version for Colab)\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "class SyntheticSceneGenerator:\n",
        "    def __init__(self, cards_dir, output_size=(640, 640)):\n",
        "        self.cards_dir = Path(cards_dir)\n",
        "        self.output_size = output_size\n",
        "        self.card_paths = list(self.cards_dir.rglob('*.jpg'))\n",
        "        print(f\"Loaded {len(self.card_paths)} card images\")\n",
        "    \n",
        "    def _get_background(self):\n",
        "        \"\"\"Generate synthetic background.\"\"\"\n",
        "        h, w = self.output_size\n",
        "        colors = [\n",
        "            (139, 90, 43), (169, 130, 91), (64, 64, 64),\n",
        "            (45, 45, 45), (20, 60, 20), (30, 30, 80),\n",
        "            (80, 80, 80), (200, 200, 200), (240, 230, 220),\n",
        "        ]\n",
        "        color = random.choice(colors)\n",
        "        color = tuple(max(0, min(255, c + random.randint(-20, 20))) for c in color)\n",
        "        bg = np.full((h, w, 3), color, dtype=np.uint8)\n",
        "        \n",
        "        # Add noise\n",
        "        noise = np.random.normal(0, 10, bg.shape).astype(np.int16)\n",
        "        bg = np.clip(bg.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "        return bg\n",
        "    \n",
        "    def generate_scene(self):\n",
        "        \"\"\"Generate a scene with 1-3 cards.\"\"\"\n",
        "        h, w = self.output_size\n",
        "        scene = self._get_background()\n",
        "        annotations = []\n",
        "        \n",
        "        num_cards = random.randint(1, 3)\n",
        "        \n",
        "        for _ in range(num_cards):\n",
        "            card_path = random.choice(self.card_paths)\n",
        "            card = cv2.imread(str(card_path))\n",
        "            if card is None:\n",
        "                continue\n",
        "            \n",
        "            # Random scale\n",
        "            scale = random.uniform(0.2, 0.5)\n",
        "            card_h, card_w = card.shape[:2]\n",
        "            new_w = int(w * scale)\n",
        "            new_h = int(new_w * card_h / card_w)\n",
        "            card = cv2.resize(card, (new_w, new_h))\n",
        "            \n",
        "            # Random rotation\n",
        "            angle = random.uniform(-30, 30)\n",
        "            center = (new_w // 2, new_h // 2)\n",
        "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "            cos, sin = abs(M[0, 0]), abs(M[0, 1])\n",
        "            rot_w = int(new_h * sin + new_w * cos)\n",
        "            rot_h = int(new_h * cos + new_w * sin)\n",
        "            M[0, 2] += (rot_w - new_w) / 2\n",
        "            M[1, 2] += (rot_h - new_h) / 2\n",
        "            card = cv2.warpAffine(card, M, (rot_w, rot_h), borderValue=(0, 0, 0))\n",
        "            \n",
        "            # Random position\n",
        "            card_h, card_w = card.shape[:2]\n",
        "            x = random.randint(0, max(0, w - card_w))\n",
        "            y = random.randint(0, max(0, h - card_h))\n",
        "            \n",
        "            # Place card on scene\n",
        "            x1, y1 = x, y\n",
        "            x2 = min(x + card_w, w)\n",
        "            y2 = min(y + card_h, h)\n",
        "            \n",
        "            card_x1 = 0\n",
        "            card_y1 = 0\n",
        "            card_x2 = x2 - x1\n",
        "            card_y2 = y2 - y1\n",
        "            \n",
        "            # Simple blend (black pixels are transparent)\n",
        "            mask = (card[card_y1:card_y2, card_x1:card_x2] > 10).all(axis=2)\n",
        "            scene[y1:y2, x1:x2][mask] = card[card_y1:card_y2, card_x1:card_x2][mask]\n",
        "            \n",
        "            # Calculate bounding box (YOLO format)\n",
        "            cx = (x1 + x2) / 2 / w\n",
        "            cy = (y1 + y2) / 2 / h\n",
        "            bw = (x2 - x1) / w\n",
        "            bh = (y2 - y1) / h\n",
        "            \n",
        "            if bw > 0.05 and bh > 0.05:  # Filter tiny boxes\n",
        "                annotations.append((0, cx, cy, bw, bh))\n",
        "        \n",
        "        return scene, annotations\n",
        "    \n",
        "    def generate_dataset(self, output_dir, num_train=5000, num_val=1000):\n",
        "        \"\"\"Generate complete YOLO dataset.\"\"\"\n",
        "        output_dir = Path(output_dir)\n",
        "        \n",
        "        for split, num in [('train', num_train), ('val', num_val)]:\n",
        "            images_dir = output_dir / split / 'images'\n",
        "            labels_dir = output_dir / split / 'labels'\n",
        "            images_dir.mkdir(parents=True, exist_ok=True)\n",
        "            labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            print(f\"\\nGenerating {split} set ({num} images)...\")\n",
        "            for i in tqdm(range(num)):\n",
        "                scene, annotations = self.generate_scene()\n",
        "                \n",
        "                cv2.imwrite(str(images_dir / f'{i:05d}.jpg'), scene)\n",
        "                \n",
        "                with open(labels_dir / f'{i:05d}.txt', 'w') as f:\n",
        "                    for ann in annotations:\n",
        "                        f.write(f'{ann[0]} {ann[1]:.6f} {ann[2]:.6f} {ann[3]:.6f} {ann[4]:.6f}\\n')\n",
        "        \n",
        "        # Create data.yaml\n",
        "        data_yaml = f\"\"\"path: {output_dir.absolute()}\n",
        "train: train/images\n",
        "val: val/images\n",
        "names:\n",
        "  0: card\n",
        "nc: 1\n",
        "\"\"\"\n",
        "        with open(output_dir / 'data.yaml', 'w') as f:\n",
        "            f.write(data_yaml)\n",
        "        \n",
        "        print(f\"\\nDataset saved to {output_dir}\")\n",
        "        print(f\"Data config: {output_dir / 'data.yaml'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic dataset\n",
        "generator = SyntheticSceneGenerator(\n",
        "    cards_dir=Path(WORK_DIR) / 'data/images/riftbound',\n",
        "    output_size=(640, 640)\n",
        ")\n",
        "\n",
        "generator.generate_dataset(\n",
        "    output_dir=Path(WORK_DIR) / 'data/detection',\n",
        "    num_train=5000,  # Reduce for faster testing, increase to 10000 for full training\n",
        "    num_val=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some generated scenes\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "detection_dir = Path(WORK_DIR) / 'data/detection/train/images'\n",
        "sample_images = list(detection_dir.glob('*.jpg'))[:6]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "for ax, img_path in zip(axes.flat, sample_images):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title(img_path.name)\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Initialize model\n",
        "model = YOLO('yolov8n.pt')  # nano model for mobile\n",
        "\n",
        "# Train\n",
        "results = model.train(\n",
        "    data=str(Path(WORK_DIR) / 'data/detection/data.yaml'),\n",
        "    epochs=100,  # Reduce for testing\n",
        "    imgsz=640,\n",
        "    batch=32,\n",
        "    optimizer='AdamW',\n",
        "    lr0=0.001,\n",
        "    weight_decay=0.0005,\n",
        "    warmup_epochs=5,\n",
        "    patience=20,\n",
        "    project=str(Path(WORK_DIR) / 'runs/detection'),\n",
        "    name='card_detector',\n",
        "    exist_ok=True,\n",
        "    # Augmentation\n",
        "    hsv_h=0.02,\n",
        "    hsv_s=0.8,\n",
        "    hsv_v=0.5,\n",
        "    degrees=30,\n",
        "    translate=0.15,\n",
        "    scale=0.6,\n",
        "    shear=10,\n",
        "    perspective=0.002,\n",
        "    flipud=0.0,\n",
        "    fliplr=0.5,\n",
        "    mosaic=0.9,\n",
        "    mixup=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate\n",
        "metrics = model.val()\n",
        "print(f\"\\nValidation Results:\")\n",
        "print(f\"  mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"  mAP50-95: {metrics.box.map:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Export Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CoreML (iOS)\n",
        "model.export(format='coreml', imgsz=640, int8=True)\n",
        "\n",
        "# Export to TFLite (Android)\n",
        "model.export(format='tflite', imgsz=640, int8=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copy model to Drive\n",
        "run_dir = Path(WORK_DIR) / 'runs/detection/card_detector'\n",
        "drive_models = Path(DRIVE_PROJECT) / 'models/detection'\n",
        "drive_models.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy best model\n",
        "shutil.copy(run_dir / 'weights/best.pt', drive_models / 'best.pt')\n",
        "print(f\"Model saved to Drive: {drive_models / 'best.pt'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Test Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test on some images\n",
        "test_images = list((Path(WORK_DIR) / 'data/detection/val/images').glob('*.jpg'))[:4]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "for ax, img_path in zip(axes.flat, test_images):\n",
        "    results = model(str(img_path))\n",
        "    annotated = results[0].plot()\n",
        "    ax.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
